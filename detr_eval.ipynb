{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETR Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows to evaluate the finetuned model with a portion of the training dataset\n",
    "\n",
    "The only metric for this evaluation is IOU (Intersection over union), because the DETR is only generating bounding boxes, not the label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 11:52:46.909937: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-03 11:52:47.811827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/home/ralvarez22/Documentos/trocr_hand/trocr_llm/datasets/cursive_hand_coco/train\"\n",
    "ANNOTATION_FILE_NAME = \"_annotations.coco.json\"\n",
    "HF_CACHE = \"/home/ralvarez22/Documentos/llm_data/llm_cache\"\n",
    "DEVICE = \"cuda\"\n",
    "CHECKPOINT = '/home/ralvarez22/Documentos/trocr_hand/trocr_llm/finetuned/detr/Akivili/V_2'\n",
    "CONFIDENCE_TRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = os.path.join(DATASET_DIR, ANNOTATION_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json = json.load(open(DATASET_FILE, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_json[\"info\"]\n",
    "del dataset_json[\"licenses\"]\n",
    "del dataset_json[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'annotations'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_json[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_boxes = []\n",
    "for e in dataset_json[\"images\"]:\n",
    "    image_annotations = [ x for x in dataset_json[\"annotations\"] if x[\"image_id\"] == e[\"id\"] ]\n",
    "    images_with_boxes.append({\n",
    "        \"id\": e[\"id\"],\n",
    "        \"image\": e[\"file_name\"],\n",
    "        \"boxes\": image_annotations\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_eval = int(len(images_with_boxes) * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = random.sample(images_with_boxes, items_to_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_proc = DetrImageProcessor.from_pretrained(CHECKPOINT, local_files_only=True)\n",
    "detr_model = DetrForObjectDetection.from_pretrained(\n",
    "    pretrained_model_name_or_path=CHECKPOINT, \n",
    "    ignore_mismatched_sizes=True, local_files_only=True\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(gt, pred):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x_a = max(gt[0], pred[0])\n",
    "    y_a = max(gt[1], pred[1])\n",
    "    x_b = min(gt[2], pred[2])\n",
    "    y_b = min(gt[3], pred[3])\n",
    "    # if there is no overlap between predicted and ground-truth box\n",
    "    if x_b < x_a or y_b < y_a:\n",
    "        return 0.0\n",
    "    # compute the area of intersection rectangle\n",
    "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    box_a_area = (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1)\n",
    "    box_b_area = (pred[2] - pred[0] + 1) * (pred[3] - pred[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bboxes(image):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # load image and predict\n",
    "        inputs = detr_proc(images=image, return_tensors='pt').to(DEVICE)\n",
    "        outputs = detr_model(**inputs)\n",
    "\n",
    "        # post-process\n",
    "        target_sizes = torch.tensor([image.shape[:2]]).to(DEVICE)\n",
    "        results = detr_proc.post_process_object_detection(\n",
    "            outputs=outputs, \n",
    "            threshold=CONFIDENCE_TRESHOLD, \n",
    "            target_sizes=target_sizes\n",
    "        )[0]\n",
    "    return results[\"scores\"], results[\"boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_iou(target_boxes, generated_boxes):\n",
    "    image_iou = 0\n",
    "    for gt_box in target_boxes:\n",
    "        for gen_box in generated_boxes:\n",
    "            tgt_box = gt_box.tolist()\n",
    "            pred_box = gen_box.tolist()\n",
    "            # The model and the dataset contains the following format for the bounding boxes:\n",
    "            # X Top Left, Y Top Left, Width, Height\n",
    "            # To match the correct format, I apply a transform to get the following:\n",
    "            # X Top Left, Y Top Left, X Bottom Right, Y Bottom Right\n",
    "            # --> XTL, YTL, XTL + Width, YTL + Height\n",
    "            xy_tg_box = [ tgt_box[0], tgt_box[1], tgt_box[0] + tgt_box[2], tgt_box[1] + tgt_box[3] ]\n",
    "            xy_pred_box = [ pred_box[0], pred_box[1], pred_box[0] + pred_box[2], pred_box[1] + pred_box[3] ]\n",
    "            iou = intersection_over_union(xy_tg_box, xy_pred_box)\n",
    "            if iou > 0:\n",
    "                image_iou += iou\n",
    "    return image_iou / len(target_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item IOU: 0.4643\n",
      "Item IOU: 0.3287\n",
      "Item IOU: 0.4593\n",
      "Item IOU: 0.2956\n",
      "Item IOU: 0.3990\n",
      "Item IOU: 0.3272\n",
      "Item IOU: 0.4109\n",
      "Item IOU: 0.3832\n",
      "Item IOU: 0.4066\n",
      "Item IOU: 0.4713\n",
      "Item IOU: 0.2625\n",
      "Item IOU: 0.4241\n",
      "Item IOU: 0.4225\n",
      "Item IOU: 0.3209\n",
      "Item IOU: 0.4025\n",
      "Item IOU: 0.4129\n",
      "Item IOU: 0.4049\n",
      "Item IOU: 0.3520\n",
      "Item IOU: 0.3868\n",
      "Item IOU: 0.2751\n",
      "Item IOU: 0.3477\n",
      "Item IOU: 0.3817\n",
      "Item IOU: 0.4049\n",
      "Item IOU: 0.4524\n",
      "Item IOU: 0.4289\n",
      "Item IOU: 0.4018\n",
      "Item IOU: 0.5095\n",
      "Item IOU: 0.4304\n",
      "Item IOU: 0.2751\n",
      "Item IOU: 0.3535\n",
      "Item IOU: 0.3501\n",
      "Item IOU: 0.4622\n",
      "Item IOU: 0.3215\n",
      "Item IOU: 0.4121\n",
      "Item IOU: 0.2989\n",
      "Item IOU: 0.2586\n",
      "Item IOU: 0.3059\n",
      "Item IOU: 0.3760\n",
      "Item IOU: 0.3524\n",
      "Item IOU: 0.3494\n",
      "Item IOU: 0.3382\n",
      "Item IOU: 0.2941\n",
      "Item IOU: 0.2637\n",
      "Item IOU: 0.3223\n",
      "Item IOU: 0.3005\n",
      "Item IOU: 0.4123\n",
      "Item IOU: 0.4226\n",
      "Item IOU: 0.3543\n",
      "Item IOU: 0.3164\n",
      "Item IOU: 0.3735\n",
      "Item IOU: 0.3452\n",
      "Item IOU: 0.3911\n",
      "Item IOU: 0.3468\n"
     ]
    }
   ],
   "source": [
    "iou_prom = 0\n",
    "for test_item in dataset_test:\n",
    "    # For every item, I test the expected or ground truth box with all the generated boxes from the model\n",
    "    # The main reason is because the model ignores the 'num_queries' configuration and generates all the posible bounding boxes\n",
    "    gt_boxes = torch.tensor([ x[\"bbox\"] for x in test_item[\"boxes\"] ], device=DEVICE)\n",
    "    input_image = os.path.join(DATASET_DIR, test_item[\"image\"])\n",
    "    image_pixels = cv2.imread(input_image)\n",
    "    _, pred_boxes = generate_bboxes(image_pixels)\n",
    "    \n",
    "    item_iou = get_image_iou(gt_boxes, pred_boxes)\n",
    "    print(\"Item IOU: {:.4f}\".format(item_iou))\n",
    "    \n",
    "    iou_prom += item_iou / len(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR Avegarage IOU: 0.3691\n"
     ]
    }
   ],
   "source": [
    "print(\"DETR Avegarage IOU: {:.4f}\".format(iou_prom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-kernel",
   "language": "python",
   "name": "dev-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
